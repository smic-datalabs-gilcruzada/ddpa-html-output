{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b07c473",
   "metadata": {},
   "source": [
    "# Data Discovery Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747d08c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4463a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import bson\n",
    "import gzip\n",
    "\n",
    "# Dev\n",
    "from ddpa_report import htmlGenerator as hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1adc829f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def read_bson_file(path):\n",
    "    with gzip.open(path, 'rb') as f_in:\n",
    "        data = bson.decode_all(f_in.read())\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "class FileHandler:\n",
    "    def __init__(self):\n",
    "        self.readers = {\n",
    "            'csv': self.read_csv_files_dataframe,\n",
    "            'excel': self.read_excel_files_dataframe,\n",
    "            'parquet': self.read_parquet_files_dataframe,\n",
    "        }\n",
    "    \n",
    "    #def get_files(self, folder_path):\n",
    "        #return [filename for filename in os.listdir(folder_path)]\n",
    "    \n",
    "    # Scans the files insider a folder_path\n",
    "    def get_files(self, folder_path):\n",
    "        files = [filename for filename in os.listdir(folder_path)]\n",
    "        full_paths = [os.path.join(folder_path, file) for file in files]\n",
    "        return full_paths\n",
    "    \n",
    "    # Using pandas function to read parquet files\n",
    "    def read_parquet_files_dataframe(self, files):\n",
    "        dataframes = []\n",
    "        for file in files:\n",
    "            table = pd.read_parquet(file)\n",
    "            dataframes.append(table)\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Using pandas function to read csv files\n",
    "    def read_csv_files_dataframe(self, files):\n",
    "        dataframes = []\n",
    "        for file in files:\n",
    "            table = pd.read_csv(file)\n",
    "            dataframes.append(table)\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Using pandas function to read excel files\n",
    "    def read_excel_files_dataframe(self, files):\n",
    "        dataframes = []\n",
    "        for file in files:\n",
    "            table = pd.read_excel(file_path)\n",
    "            dataframes.append(table)\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Reads the files inside the folder and maps it to the appropriate pandas load function\n",
    "    def read_list_files(self, files, file_type):\n",
    "        if file_type not in self.readers:\n",
    "            raise ValueError(f\"Unsupported file type '{file_type}'. Supported types are: {', '.join(self.readers.keys())}\")\n",
    "        return self.readers[file_type](files)  # Adjust header parameter as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee6cff59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataDiscovery:   \n",
    "    # Formatting Functions\n",
    "    # Formats the return of pandas' min() and max() functions into string for better readability\n",
    "    @staticmethod\n",
    "    def format_float(value):\n",
    "        return str(value)\n",
    "    \n",
    "    # Replaces values under column with empty strings into null/none\n",
    "    @staticmethod\n",
    "    def replace_empty_strings_with_null(data_frame):\n",
    "        return data_frame.replace('', None)\n",
    "    \n",
    "    # Export Function\n",
    "    def create_excel_sheet(self, dataframe_dict, distrib_dict, output_file):\n",
    "        \n",
    "        metrics_df_width = len(dataframe_dict['metrics_df'].columns)\n",
    "        metrics_df_length = (len(dataframe_dict['metrics_df']) + 2) + len(dataframe_dict['dataset_overview'])\n",
    "        \n",
    "        # Create an Excel writer object\n",
    "        excel_writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "\n",
    "        # Write the basic dataset_overview to the Excel sheet\n",
    "        dataframe_dict['dataset_overview'].to_excel(excel_writer, sheet_name='Sheet1', startrow = 0, startcol = 1, index=False)\n",
    "\n",
    "        # Write the metrics_df below dataset_overview\n",
    "        dataframe_dict['metrics_df'].to_excel(excel_writer, sheet_name='Sheet1', startrow=len(dataframe_dict['dataset_overview']) + 2, index=True)\n",
    "        \n",
    "        # Write the date_format_df next to the metrics_df\n",
    "        dataframe_dict['date_format_df'].to_excel(excel_writer, sheet_name='Sheet1', \n",
    "                                                  # startrow=len(dataframe_dict['smac_format_df']) + 2,\n",
    "                                                  startcol = metrics_df_width + 2, \n",
    "                                                  index=False)\n",
    "        \n",
    "        # Write the data_report_df next to the date_format_df\n",
    "        dataframe_dict['date_report_df'].to_excel(excel_writer, sheet_name='Sheet1', \n",
    "                                                  # startrow = len(dataframe_dict['smac_format_df']) + 2,\n",
    "                                                  startcol = (metrics_df_width + 2) + len(dataframe_dict['date_format_df']),\n",
    "                                                  index = False)\n",
    "        \n",
    "        # Write the smac_format_df below date_format_df\n",
    "        dataframe_dict['smac_format_df'].to_excel(excel_writer, sheet_name='Sheet1', \n",
    "                                                  startrow=len(dataframe_dict['date_format_df']) + 2,\n",
    "                                                  startcol= metrics_df_width + 2, \n",
    "                                                  index=False)\n",
    "          \n",
    "        # Write the smac_report_df next to smart_format_df\n",
    "        dataframe_dict['smac_report_df'].to_excel(excel_writer, sheet_name='Sheet1', \n",
    "                                                  startrow = len(dataframe_dict['date_format_df']) + 2,\n",
    "                                                  startcol = (metrics_df_width + 2) + len(dataframe_dict['date_format_df']),\n",
    "                                                  index = False)\n",
    "        \n",
    "        distrib_col_width = 0\n",
    "        counter_width = 0\n",
    "        \n",
    "        # Excel Formatting for Distribution Columns\n",
    "        for key, value in distrib_dict.items():\n",
    "            value.to_excel(\n",
    "                excel_writer, sheet_name = 'Sheet1',\n",
    "                startrow = metrics_df_length + 2,\n",
    "                startcol = distrib_col_width,\n",
    "                index = False\n",
    "            )\n",
    "            \n",
    "            distrib_col_width += (len(value.columns) + 1) \n",
    "        \n",
    "         \n",
    "        # Get the xlsxwriter workbook and worksheet objects\n",
    "        workbook = excel_writer.book\n",
    "        worksheet = excel_writer.sheets['Sheet1']\n",
    "\n",
    "        # Random formatting on excel\n",
    "        format_bold = workbook.add_format({'bold': True})\n",
    "        worksheet.set_column('A:A', 20, format_bold)\n",
    "\n",
    "        # Close the Excel writer\n",
    "        excel_writer.close()\n",
    "                \n",
    "   # Main Function\n",
    "    def discovery_summary(self, dataframe, smac_column, phone_no_column, date_columns, distrib_columns, output_file):\n",
    "        discovery_data_frame = self.replace_empty_strings_with_null(dataframe)\n",
    "        \n",
    "        # Attribute metrics\n",
    "        # Get number of rows and columns\n",
    "        num_rows, num_columns = discovery_data_frame.shape\n",
    "        \n",
    "        # Get data types per column\n",
    "        data_types = discovery_data_frame.dtypes\n",
    "        \n",
    "        # Count number of unique values per column\n",
    "        unique_values = discovery_data_frame.nunique()\n",
    "        \n",
    "        # Count nullity of columns\n",
    "        nullity_summary = discovery_data_frame.isnull().sum()\n",
    "        \n",
    "        # Calculates for the percentage of nullity per column\n",
    "        null_percentage = (nullity_summary / num_rows * 100).apply(lambda x: f'{x:.2f}%')\n",
    "\n",
    "        # Get min and max values of each column\n",
    "        min_values = discovery_data_frame.min(numeric_only=True).apply(self.format_float)\n",
    "        max_values = discovery_data_frame.max(numeric_only=True).apply(self.format_float)\n",
    "\n",
    "        # Get most frequent value in each column\n",
    "        most_frequent_values = discovery_data_frame.mode().iloc[0]\n",
    "\n",
    "        metrics_data = {\n",
    "            'Data Type': data_types,\n",
    "            'Unique Values': unique_values,\n",
    "            'Null/Empty Counts': nullity_summary,\n",
    "            'Null Percentage': null_percentage,\n",
    "            'Min Values': min_values,\n",
    "            'Max Values': max_values,\n",
    "            'Most Frequent Values': most_frequent_values\n",
    "        }\n",
    "\n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "        # Dataset Overview\n",
    "        num_duplicates = discovery_data_frame.duplicated().sum()\n",
    "        \n",
    "        overview = {\n",
    "            \"Number of Columns\": [num_columns],\n",
    "            \"Number of Rows\": [num_rows],\n",
    "            \"Duplicates\": [num_duplicates]\n",
    "        }\n",
    "\n",
    "        # Checking Formats\n",
    "        fc = FormatChecker()\n",
    "\n",
    "        # Calls the SMAC validation functions\n",
    "        if(smac_column != None):\n",
    "            smac_format_df = fc.get_smac_formats(discovery_data_frame, smac_column)\n",
    "            smac_report_df = fc.check_smac_format(discovery_data_frame, smac_column)\n",
    "        else:\n",
    "            smac_format_df = pd.DataFrame() # Empty df\n",
    "            smac_report_df = pd.DataFrame()\n",
    "\n",
    "        # Calls the phone number validation functions\n",
    "        if(phone_no_column != None):\n",
    "            phone_no_format_df = fc.get_phone_no_formats(discovery_data_frame, phone_no_column)\n",
    "        else:\n",
    "            phone_no_format_df = pd.DataFrame() # Empty df\n",
    "        \n",
    "        # Calls the date column validation functions\n",
    "        date_report_df, date_format_df = fc.check_date_format(discovery_data_frame, date_columns)\n",
    "    \n",
    "        dataset_overview_df = pd.DataFrame(overview)\n",
    "        \n",
    "        # Create a dictionary of DataFrames\n",
    "        dataframes_dict = {\n",
    "            'dataset_overview': dataset_overview_df,\n",
    "            'metrics_df': metrics_df,\n",
    "            'smac_report_df': smac_report_df,\n",
    "            'smac_format_df': smac_format_df,\n",
    "            'phone_no_format_df': phone_no_format_df,\n",
    "            'date_report_df': date_report_df,\n",
    "            'date_format_df': date_format_df\n",
    "        }\n",
    "        \n",
    "        \n",
    "        dict_of_distrib_df = {}  # Create an empty dictionary\n",
    "\n",
    "        # Distribution Dataframes\n",
    "        for cols in distrib_columns:\n",
    "            df_name = cols\n",
    "            df_data = self.column_distribution(discovery_data_frame, cols)\n",
    "            dict_of_distrib_df[df_name] = df_data  # Add the DataFrame to the dictionary with its name as the key\n",
    "\n",
    "        # Print dataframe names in dictionary (debugging)\n",
    "        #print(dict_of_distrib_df.keys())\n",
    "\n",
    "        # self.create_excel_sheet(dataframes_dict, dict_of_distrib_df, output_file)\n",
    "        hg.generate_report(overview)\n",
    "        return metrics_df\n",
    "    \n",
    "    def column_distribution(self, df, column_name):\n",
    "        # Using groupby to count the distribution of values under a column\n",
    "        distrib_df = df.groupby(column_name).size().reset_index(name='count')\n",
    "        \n",
    "        # Descending sort\n",
    "        distrib_df = distrib_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "        # Getting total_count of values for percentage calculation\n",
    "        total_entries = distrib_df['count'].sum()\n",
    "\n",
    "        # Add a new column with the percentage values\n",
    "        distrib_df['percentage'] = (distrib_df['count'] / total_entries * 100).map('{:.2f}%'.format)\n",
    "\n",
    "        return distrib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81ee340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FormatChecker:\n",
    "    \n",
    "    def get_smac_formats(self, dataframe, column_name):\n",
    "        smac_no_list = []\n",
    "        smac_length_list = []\n",
    "        \n",
    "        # Iterates though the smac_no column\n",
    "        for smac in dataframe[column_name]:\n",
    "            \n",
    "            # Turning datetime object to string\n",
    "            smac_str = str(smac)\n",
    "\n",
    "            # Skips null values\n",
    "            if pd.notna(smac):\n",
    "                \n",
    "                # Gets the first three characters in a smac_no value\n",
    "                smac_no_list.append(smac_str[:3])\n",
    "                \n",
    "                # Gets the length of a given smac_no\n",
    "                smac_length_list.append(len(smac_str))\n",
    "\n",
    "        smac_format_dict = {\n",
    "            'smac_first_three_idx': smac_no_list,\n",
    "            'smac_no_length': smac_length_list\n",
    "        }\n",
    "\n",
    "        smac_format_df = pd.DataFrame(smac_format_dict)\n",
    "        \n",
    "        # Groupby in accordance to length and the first_three_idx found in smac_no\n",
    "        final_df = smac_format_df.groupby(['smac_first_three_idx', 'smac_no_length']).size().reset_index(name='frequency')\n",
    "\n",
    "        return final_df\n",
    "    \n",
    "    def all_digits(self, phone_no_str):\n",
    "        # Regex for numbers and a optional '+' sign\n",
    "        pattern = r'^\\+[0-9]+$'\n",
    "        \n",
    "        # Use re.match to check if the entire string matches the pattern\n",
    "        if re.match(pattern, phone_no_str):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_phone_no_formats(self, dataframe, column_name):\n",
    "        phone_idx_list = []\n",
    "        phone_length_list = []\n",
    "        is_all_digit = []\n",
    "        \n",
    "        # Iterates through the phone_no column\n",
    "        for phone_number in dataframe[column_name]:\n",
    "            \n",
    "            # Casting the phone_no value into a string\n",
    "            phone_number_str = str(phone_number)\n",
    "            \n",
    "            # Skips null values\n",
    "            if pd.notna(phone_number):\n",
    "                \n",
    "                # Gets the first character of a given phone_no\n",
    "                phone_idx_list.append(phone_number_str[0])\n",
    "                \n",
    "                # Gets the length of a given phone_no\n",
    "                phone_length_list.append(len(phone_number_str))\n",
    "    \n",
    "                # Flags true if phone_no is numericals only with occasional '+' sign \n",
    "                if(fc.all_digits(phone_number_str)):\n",
    "                    is_all_digit.append(1)\n",
    "                else:\n",
    "                    is_all_digit.append(0)\n",
    "                    \n",
    "        phone_format_dict = {\n",
    "            'phone_first_idx': phone_idx_list,\n",
    "            'phone_no_length': phone_length_list,\n",
    "            'is_all_digit': is_all_digit\n",
    "        }\n",
    "        \n",
    "        phone_format_df = pd.DataFrame(phone_format_dict)\n",
    "        \n",
    "        # A groupby for all_digit flag, phone_no_length, and the phone_no's first index\n",
    "        final_phone_df = phone_format_df.groupby(['phone_first_idx', 'phone_no_length', 'is_all_digit']).size().reset_index(name='frequency')\n",
    "        \n",
    "        return final_phone_df\n",
    "            \n",
    "    \n",
    "    # SMAC_NO Format Checker\n",
    "    def check_smac_format(self, dataframe, column_name):\n",
    "        total_count = dataframe[column_name].notnull().sum()\n",
    "        correct_count = 0\n",
    "        correct_values = []\n",
    "        incorrect_values = []\n",
    "\n",
    "        # Iterates through the smac_no column\n",
    "        for number in dataframe[column_name]:\n",
    "            \n",
    "            # Casting smac_no value into a string\n",
    "            number_str = str(number)\n",
    "            \n",
    "            # Skips null values\n",
    "            if pd.notna(number):\n",
    "                \n",
    "                # checks if given smac_no is 16 digits and starts wiht 8\n",
    "                if len(number_str) == 16 and number_str[0] == '8':\n",
    "                    correct_count += 1\n",
    "                    correct_values.append(number)\n",
    "                else:\n",
    "                    incorrect_values.append(number)\n",
    "\n",
    "        incorrect_count = total_count - correct_count\n",
    "        correct_percentage = ((correct_count / total_count) * 100)\n",
    "        incorrect_percentage = 100 - correct_percentage\n",
    "        \n",
    "        \n",
    "        smac_report_dict = {\n",
    "            'smac_correct_count': correct_count,\n",
    "            'correct_percentage': correct_percentage,\n",
    "            'smac_incorrect_count': incorrect_count,\n",
    "            'incorrect_percentage': incorrect_percentage\n",
    "        }\n",
    "\n",
    "        smac_report_df = pd.DataFrame([smac_report_dict])\n",
    "        correct_df = pd.DataFrame({column_name: correct_values})\n",
    "        incorrect_df = pd.DataFrame({column_name: incorrect_values})\n",
    "\n",
    "        return smac_report_df\n",
    "    \n",
    "    # Date Format Checker\n",
    "    def has_valid_delimiter(self, date_str):\n",
    "        # Check if the date string contains '-' as delimiters\n",
    "        return '-' in date_str\n",
    "\n",
    "    def check_date_format(self, dataframe, column_names):\n",
    "        date_format = '%Y-%m-%d'\n",
    "\n",
    "        all_date_reports = []\n",
    "        all_final_date_formats = []\n",
    "        \n",
    "        \n",
    "        # Iterates through the columns where there are dates\n",
    "        for column_name in column_names:\n",
    "            total_count = dataframe[column_name].notnull().sum()\n",
    "            correct_count = 0\n",
    "            correct_values = []\n",
    "            incorrect_values = []\n",
    "            date_delimiters = []\n",
    "            column_for_date_str = []\n",
    "            \n",
    "            # Iterates through date values under the date column\n",
    "            for date in dataframe[column_name]:\n",
    "                \n",
    "                # Skips null values\n",
    "                if pd.notna(date):\n",
    "                    \n",
    "                    # Turning datetime format into string\n",
    "                    date_str = str(date)\n",
    "\n",
    "                    # Scans the date string for any possible delimiter\n",
    "                    delimiters = [char for char in date_str if not char.isalnum()]\n",
    "\n",
    "                    # Checks if a given date_string has the appriopriate delimiter\n",
    "                    if fc.has_valid_delimiter(date_str):\n",
    "                        \n",
    "                        # If it has the appropriate delimiter, we check for the y/m/d format\n",
    "                        try:\n",
    "                            pd.to_datetime(date_str, format=date_format)\n",
    "                            correct_count += 1\n",
    "                            correct_values.append(date)\n",
    "                            column_for_date_str.append(date)\n",
    "\n",
    "                            # Gets the first delimiter found in a date string\n",
    "                            if delimiters:\n",
    "                                \n",
    "                                # Append the first delimiter found to date_delimiters\n",
    "                                date_delimiters.append(delimiters[0])\n",
    "                            else:\n",
    "                                \n",
    "                                # Handle the case where there are no delimiters\n",
    "                                date_delimiters.append(\"No delimiter found\")\n",
    "\n",
    "                        # If the date_string has the wrong y/m/d format, we tag as incorrect\n",
    "                        except ValueError:\n",
    "                            incorrect_values.append(date)\n",
    "                            column_for_date_str.append(date)\n",
    "                            \n",
    "                            if delimiters:\n",
    "                                date_delimiters.append(delimiters[0])\n",
    "                            else:\n",
    "                                date_delimiters.append(\"No delimiter found\")\n",
    "                        \n",
    "                    # If the date_string doesn't have the appropriate delimiter, we tag as incorrect value\n",
    "                    else:\n",
    "                        incorrect_values.append(date)\n",
    "                        column_for_date_str.append(date)\n",
    "                        \n",
    "                        # We get the delimiter that appeared on the given date_string\n",
    "                        if delimiters:\n",
    "                                date_delimiters.append(delimiters[0])\n",
    "                        else:\n",
    "                            date_delimiters.append(\"No delimiter found\")\n",
    "\n",
    "            incorrect_count = total_count - correct_count\n",
    "            correct_percentage = ((correct_count / total_count) * 100)\n",
    "            incorrect_percentage = 100 - correct_percentage\n",
    "\n",
    "            date_report_dict = {\n",
    "                'column_name': column_name,\n",
    "                'correct_date_format_count': correct_count,\n",
    "                'correct_percentage': correct_percentage,\n",
    "                'incorrect_date_format_count': incorrect_count,\n",
    "                'incorrect_percentage': incorrect_percentage\n",
    "            }\n",
    "\n",
    "            date_format_dict = {\n",
    "                'column_name': column_name,\n",
    "                'date_delimiters': date_delimiters,\n",
    "            }\n",
    "\n",
    "            date_format_df = pd.DataFrame(date_format_dict)\n",
    "\n",
    "            final_date_format_df = date_format_df.groupby(['date_delimiters']).size().reset_index(name='frequency')\n",
    "            \n",
    "            # Use transform to create a new 'column_name' column\n",
    "            final_date_format_df['column_name'] = date_format_df.groupby('date_delimiters')['column_name'].transform('first')\n",
    "\n",
    "            date_report_df = pd.DataFrame([date_report_dict])\n",
    "\n",
    "            all_date_reports.append(date_report_df)\n",
    "            all_final_date_formats.append(final_date_format_df)\n",
    "\n",
    "        # Combine the results for all columns\n",
    "        combined_date_reports = pd.concat(all_date_reports, ignore_index=True)\n",
    "        combined_final_date_formats = pd.concat(all_final_date_formats, ignore_index=True)\n",
    "\n",
    "        return combined_date_reports, combined_final_date_formats\n",
    "    # Example usage:\n",
    "    # date_report_df, final_date_format_df = check_date_format(your_dataframe, ['column1', 'column2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8cb8405",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 7.556441783905029\n"
     ]
    }
   ],
   "source": [
    "dg = DataDiscovery()\n",
    "fh = FileHandler()\n",
    "fc = FormatChecker()\n",
    "from ddpa_report import htmlGenerator as hg\n",
    "\n",
    "# output_file = 'LOYALTIES_TABLE_METRICS_OUTPUT.xlsx'\n",
    "loyalties = r\"C:\\Users\\gil.cruzada\\Desktop\\Aquisition Development\\DDPA; HTML Output\\loyalties.bson.gz\"\n",
    "loyalties_df = read_bson_file(loyalties)\n",
    "\n",
    "date_columns = ['expiry', 'dateAdded']\n",
    "smac_column = 'cardNumber'\n",
    "phone_no_column = None\n",
    "distrib_columns = ['seqNo', 'type', 'isExpired']\n",
    "\n",
    "start = time.time()\n",
    "dg.discovery_summary(loyalties_df, smac_column, phone_no_column, date_columns, distrib_columns, output_file)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Runtime: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628f93a",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95de43-f14f-4f3b-9ee1-0bdf7c79b838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445863ed-3c0b-44eb-80e0-a41592809aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
